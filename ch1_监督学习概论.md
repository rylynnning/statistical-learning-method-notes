[toc]

#### 1.1 统计学习

#### 1.2 统计学习的分类

* **基本分类**：
    * **监督学习**
    * **无监督学习**
    * **强化学习**：智能系统在与环境的连续互动中学习最优行为策略的机器学习问题，本质是学习<u>最优的序贯决策</u>，目标是<u>长期积累奖励的最大化</u>
        * 状态价值函数：策略从某一状态$s$开始的长期累计奖励的数学期望:$v_\pi(s) = E_\pi[r_{t+1}+\gamma  r_{t+2}+\gamma ^2 r_{t+3}+...\mid s_t=s]$
        * 动作价值函数：策略$\pi$的从某一状态$s$和动作$a$开始的长期累积奖励的数学期望:$q_\pi (s,a) = E_\pi[r_{t+1}+\gamma r_{t+2}+\gamma ^2 r_{t+3}+...\mid s_t=a,a_t=a]$
    * 半监督学习：少量标注数据、大量未标注数据；只在利用未标注数据中的信息，辅助标注数据，进行监督学习，以较低的成本达到较好的学习效果
    * 主动学习：机器不断给出实例让教师进行标注，再利用标注数据学习预测模型；目标是找出对学习最有帮助的实例来标注，以较小的标注代价达到较好的学习效果
        

* 按**模型**分类：
    * 概率模型&非概率模型：监督学习中，概率模型是生成模型，非概率模型是判别模型；概率模型可以表示为联合概率分布的形式
    * 线性模型&非线性模型
    * 参数化模型&非参数化模型：
        * 参数化模型：假设模型参数的维度固定，模型可以由有限维参数完全刻画
        * 非参数化模型：假设模型参数的维数不固定或无穷大，随着训练数据量的增加而不断扩大
* 按**算法**分类：
    * 在线学习：每次接收一个样本进行预测，之后学习模型并不断重复此操作
    * 批量学习：一次接收所有数据学习模型，再进行预测
* 按**技巧**分类：
    * 贝叶斯学习：
        * 思想：在概率模型中，利用贝叶斯定理计算后验概率，并利用该原理进行模型估计，以及对数据的预测
        * 特点：将模型、未观测要素及其参数用变量表示，使用模型的先验分布
    * 核方法：使用核函数表示和学习非线性模型
        * 在把线性模型扩展到非线性模型的过程中，不显式定义这个映射，而是定义核函数，即映射之后在特征空间的内积

#### 1.3 统计学习方法三要素

> **方法 = 模型 + 策略 + 算法**
* **模型**：
    * 模型：所要学习的条件概率分布或决策函数
    * 假设空间：包含所有可能的条件概率分布或决策函数（即，决策函数或条件概率的集合）
        * 决策函数型：$\mathcal{F}=\{ f\mid Y=f_\theta (X),\theta \in \bold{R} ^n \}$
        * 条件概率型：$\mathcal{F}=\{ P\mid P_\theta (Y\mid X),\theta \in \bold{R}^n\}$
    
* **策略**：
    * 损失函数&风险函数
        * 损失函数（代价函数）：度量预测错误的程度，是$f(X)$和$Y$的非负实值函数，记作$L(Y,f(X))$；损失函数值越小，模型越好
        * 风险函数（期望损失）：损失函数的期望:
            $$
            \begin{aligned}R_{exp}(f)&=E_p[L(Y,f(X))] \\
            &=\int_{\mathcal{x\times y}} L(y,f(x))P(x,y)dxdy\end{aligned}
            $$

          学习的目标就是选择期望风险最小的模型
        * 经验风险（经验损失）：模型$f(X)$关于训练数据集的平均损失：$R_{emp}(f)=\dfrac{1}{N}\displaystyle\sum_{i=1}^nL(Y_i,f(x_i))$
        * $R_{exp}(f)$是模型关于联合分布的期望损失；$R_{emp}(f)$是模型关于训练样本集的平均损失
    * 经验风险最小化&结构风险最小化：经验或结构风险函数即最优化的目标函数
        * 经验风险最小化（ERM）认为：经验风险最小的模型就是最优模型：$\displaystyle\min_{f\in \mathcal{F}}\dfrac{1}{N}\displaystyle\sum_{i=1}^nL(Y_i,f(x_i))$
        * 结构风险最小化（SRM）：等价于正则化，即，在经验风险上加上表示模型复杂度的正则化项（罚项）。
            * 结构风险定义：$R_{srm}(f)=\dfrac{1}{N}\displaystyle\sum_{i=1}^nL(Y_i,f(x_i))+\lambda J(f)$
            * 求解结构风险最小的模型：$\displaystyle\min_{f\in \mathcal{F}}\dfrac{1}{N}\displaystyle\sum_{i=1}^nL(Y_i,f(x_i))+\lambda J(f)$

* **算法**：学习模型的具体计算方法。

#### 1.4 模型评估与模型选择
* 训练误差&测试误差：假设学习到的模型为$Y=\hat{f}(X)$,则：
    * 训练误差是模型关于训练数据集的平均损失：$R_{emp}(\hat{f})=\dfrac{1}{N}\displaystyle\sum_{i=1}^NL(y_i,\hat{f}(x_i))$
    * 测试误差是模型关于测试数据集的平均损失：$e_{test}=\dfrac{1}{N'}\displaystyle\sum_{i=1}^{N'}L(y_i,\hat{f}(x_i))$
* 过拟合&模型选择：模型选择旨在避免过拟合并提高模型的预测能力
  ![33d4f27b8ac7b57b0fa52b4a49462fff.png](evernotecid://DF5EC8F8-A311-491D-B4BB-BB7FE3E3EBE4/appyinxiangcom/16888917/ENResource/p2482)@w=500
    

#### 1.5 正则化与交叉验证（模型选择方法）
* 正则化
    * 正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值越大
    * 正则化一般形式：$\displaystyle\min_{f\in \mathcal{F}}\dfrac{1}{N}\displaystyle\sum_{i=1}^nL(Y_i,f(x_i))+\lambda J(f)$，第1项是经验风险，第2项是正则化项
    * 作用：选择经验风险与模型复杂度同时比较小的模型
* 交叉验证
    * 基本想法：重复使用数据，把给定的数据切分，将切分的数据集组合为训练集与测试集，在此基础上反复进行训练、测试以及模型选择

| 简单交叉验证 | $S$折交叉验证 | 留一交叉验证 |
| --- | --- | --- |
| 将数据分为训练集和测试集，在各种条件下训练训练集得到不同的模型，在测试集上评价各个模型的测试误差，选择测试误差最小的那个 | 将已知数据切分为S个互不相交、大小相同的子集；用S-1个子集进行训练，用余下的子集测试；将这一过程对可能的S种选择重复进行，最后选出S次评测中平均测试误差最小的模型 | S折交叉验证的特殊情况，S=N（N为数据集容量），适用于数据缺乏的情况 |


#### 1.6 泛化能力
* 泛化误差
    * 泛化能力：学习到的模型对未知数据的预测能力
    * 泛化误差：用这个模型对未知数据预测的误差
     $$
     \begin{aligned}R_{exp}(\hat{f})&=E_P[L(Y,\hat{f}(X))]\\
     &=\int_{\mathcal{x\times y}}L(y,\hat{f}(x))P(x,y)dxdy\end{aligned}
     $$
* 泛化误差上界：泛化误差的概率上界，通过比较两种学习方法的泛化误差上界的大小来比较其优劣
    * 性质：泛化误差上界是样本容量的负相关函数，假设空间容量的正相关函数
    * 定理：
    $$
    \begin{aligned}R(f)\leqslant\hat{R}(f)+\varepsilon(d,N,\delta)\end{aligned}$$

#### 1.7 生成模型与判别模型

| 生成模型 | 判别模型 |
| --- | --- |
| 由数据学习联合概率分布，然后求出条件概率分布作为预测的模型 | 由数据直接学习决策函数或条件概率分布作为预测模型 |
| 模型表示了给定输入$X$产生输出$Y$的关系 | 关心的是对给定的输入$X$，应该预测什么样的输出$Y$ |
| 可以还原出联合概率分布 | 不能 |
| 学习收敛速度更快 |  |
| 存在隐变量时依然可以用生成方法 | 不能 |
|  | 学习准确率更高（因为直接面对预测） |
| | 可以简化学习问题（可以对数据进行抽象、定义和使用特征） |
#### 1.8 监督学习应用
* **分类**：当输出变量$Y$取有限个离散值时，预测问题便成为分类问题。包括**学习和分类**两个过程
    * 评价分类器性能的指标：分类准确率——分类器正确分类的样本数与总样本数之比 
        * TP：正类预测为正类数
        * FN：正类预测为负类数
        * FP：负类预测为正类数
        * TN：负类预测为负类数
    * 精确率：$P=\dfrac{TP}{TP+FP}$
    * 召回率：$R=\dfrac{TP}{TP+FN}$
    * $F_1 score$：$\dfrac{2}{F_1}=\dfrac{1}{P}+\dfrac{1}{R}$
        
* **标注**：分为**学习和标注**两个过程
    * 输入：一个观测序列
    * 输出：一个标记序列或状态序列
    * 目标：学习一个模型，使其能够对观测序列给出标记序列作为预测
    * 评价指标：与分类问题相同
    * 常用方法：隐马尔可夫模型、条件随机场
    * 适用领域：信息抽取、自然语言处理
* **回归**：用于预测输入变量和输出变量之间的关系，等价于函数拟合，即，选择一条函数曲线使其很好地拟合已知数据且很好地预测未知数据，分为**学习和预测**两个过程
    * 类别：
        * 按照输入变量个数：一元回归/多元回归
        * 按照变量关系：线性回归/非线性回归
    * 常用损失函数：平方损失函数（可用最小二乘法求解）